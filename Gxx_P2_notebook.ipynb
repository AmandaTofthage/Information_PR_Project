{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>PRI 2023/24: second\n",
    "    project delivery</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GROUP 1**\n",
    "- Amanda Tofthagen, 113124\n",
    "- Tora Kristine Løtveit, 112927\n",
    "- Tuva Grønvold Natvig, 113107"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Main facilities</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and preproccesing data (using with functions made in project 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/amandatofthagen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/amandatofthagen/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/amandatofthagen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/amandatofthagen/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "import nltk  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import ndcg_score, average_precision_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert text to lower case and tokenize\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove punctuation\n",
    "    tokens = [token for token in tokens if token not in punctuation]\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Lemmatize tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "# Load metadata as both dataframe and list\n",
    "def load_metadata(file_path):\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "    df = df[['cord_uid', 'title', 'abstract']].dropna()  # Keep only required columns\n",
    "    df['title'] = df['title'].astype(str)\n",
    "    df['abstract'] = df['abstract'].astype(str)\n",
    "\n",
    "    # Store as a list of \"title + abstract\" for ranking models\n",
    "    doc_list = df.apply(lambda x: f\"{x['title']} {x['abstract']}\", axis=1).tolist()\n",
    "    \n",
    "    return df, doc_list  # Return both formats\n",
    "\n",
    "\n",
    "# Load qrels\n",
    "def load_qrels(file_path):\n",
    "    qrels = defaultdict(dict)\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            topic_id, _, doc_id, relevance = line.strip().split()\n",
    "            qrels[topic_id][doc_id] = int(relevance)\n",
    "    return qrels\n",
    "\n",
    "def load_queries(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    queries = {}\n",
    "    for topic in root.findall('topic'):\n",
    "        topic_number = topic.get('number')\n",
    "        query_text = preprocess_text(topic.find('query').text)\n",
    "        queries[topic_number] = \" \".join(query_text)  # Ensure consistency\n",
    "    return queries\n",
    "\n",
    "metadata_path = \"data2/metadata.csv\"\n",
    "qrels_path = \"data2/qrels.txt\"\n",
    "queries_path = \"data2/topics.xml\"\n",
    "\n",
    "D, D_list = load_metadata(metadata_path)\n",
    "qrels = load_qrels(qrels_path)\n",
    "queries = load_queries(queries_path)\n",
    "\n",
    "def indexing(D):\n",
    "    start_time = time.time()  # Start timing\n",
    "    \n",
    "    # Initialize the inverted index\n",
    "    inverted_index = defaultdict(dict)\n",
    "\n",
    "    # Process each document\n",
    "    for index, row in D.iterrows():\n",
    "        # Combine title and abstract for indexing\n",
    "        document_text = f\"{row['title']} {row['abstract']}\"\n",
    "        # Preprocess text\n",
    "        tokens = preprocess_text(document_text)\n",
    "\n",
    "        # Build the index\n",
    "        for term in tokens:\n",
    "            if index in inverted_index[term]:\n",
    "                inverted_index[term][index] += 1\n",
    "            else:\n",
    "                inverted_index[term][index] = 1\n",
    "\n",
    "    # Calculate time and space used\n",
    "    indexing_time = time.time() - start_time\n",
    "    index_size = sum(sum(freq.values()) for freq in inverted_index.values())  # Calculate the size of the index\n",
    "\n",
    "    # Return the inverted index, time taken, and estimated size of the index\n",
    "    return inverted_index, indexing_time, index_size\n",
    "\n",
    "def save_index_to_json(inverted_index, file_name='inverted_index.json'):\n",
    "    with open(file_name, 'w') as f:\n",
    "        json.dump(inverted_index, f, indent=4)\n",
    "\n",
    "def save_index_to_json(inverted_index, directory='output_data', file_name='inverted_index.json'):\n",
    "    # Check if the directory exists, if not create it\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Full path to save the file\n",
    "    path_to_file = os.path.join(directory, file_name)\n",
    "\n",
    "    # Save the JSON file\n",
    "    with open(path_to_file, 'w') as f:\n",
    "        json.dump(inverted_index, f, indent=4)\n",
    "\n",
    "# Run it:\n",
    "inverted_index, time_taken, size = indexing(D)\n",
    "save_index_to_json(inverted_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part I: clustering</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A) Clustering*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B) Summarization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C) Keyword extraction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*D) Evaluation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part II: classification</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A) Feature extraction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code and statistics here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B) Classification*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C) Ranking extension*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*D) Evaluation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Question materials (optional)</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Part I: clustering</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)** Do clustering-guided summarization alters the behavior and efficacy of the IR system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2)** How sentence representations, clustering choices, and rank criteria impact summarization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**...** (additional questions with empirical results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>END</H3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
